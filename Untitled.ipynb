{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "welsh-bible",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import argparse\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "from scipy import io\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, \\\n",
    "                            balanced_accuracy_score\n",
    "# # directory reach\n",
    "# directory = Path(os.path.abspath(__file__))\n",
    "# # setting path\n",
    "# sys.path.append(os.path.abspath(directory.parent.parent.parent))\n",
    "from src.helper import read_dataset, \\\n",
    "                       load_class_attribute_matrix, \\\n",
    "                       load_classes\n",
    "from src.datasets import aPY, AwA, LAD, SUN, CUB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chubby-number",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = 'data/'\n",
    "dataset = args.data + '/'\n",
    "iterations = 1\n",
    "\n",
    "ds = read_dataset(dataset, data)\n",
    "\n",
    "images, image_idx, idx_image, imageid_class = ds.get_images()\n",
    "classes, class_idx, idx_class, classid_imageid = ds.get_classes()\n",
    "attributes, attr_idx, idx_attr, image_attr = ds.get_attributes()\n",
    "\n",
    "if dataset == 'SUN/':\n",
    "    image_attr = np.rint(image_attr)\n",
    "\n",
    "seen_samples, seen_old_to_new, seen_new_to_old = ds.get_seen_sample()\n",
    "unseen_samples, unseen_old_to_new, unseen_new_to_old = ds.get_unseen_sample()\n",
    "\n",
    "if dataset == 'AWA2/':\n",
    "    class_attributes = ds.get_class_attribute_matrix('att_splits.mat',\n",
    "                                                     continuous=True, \n",
    "                                                     bound=None, \n",
    "                                                     lb=None, ub=None)\n",
    "    class_attributes = class_attributes/100\n",
    "else:\n",
    "    class_attributes = ds.get_class_attribute_matrix(continuous=True, \n",
    "                                                     bound=None, \n",
    "                                                     lb=None, ub=None)\n",
    "    \n",
    "embeddings = ds.get_embeddings()\n",
    "\n",
    "\n",
    "data_folder = 'data/' + dataset\n",
    "\n",
    "split_file = 'att_splits.mat'\n",
    "splits = scipy.io.loadmat(f'{data}{dataset}splits/{split_file}')\n",
    "\n",
    "train = splits['trainval_loc']\n",
    "#val = splits['val_loc']\n",
    "test = splits['test_unseen_loc']\n",
    "\n",
    "np.random.seed(0)\n",
    "index_train = sorted(list(np.random.choice(list(range(train.shape[0])), \n",
    "                                           size=int(train.shape[0]/100*80), \n",
    "                                           replace=False)))\n",
    "index_val = sorted(list(set(list(range(train.shape[0]))).difference(set(index_train))))\n",
    "\n",
    "train_val = train[index_val]\n",
    "train = train[index_train]\n",
    "\n",
    "\n",
    "res = 'res101.mat'\n",
    "resnet101 = scipy.io.loadmat(f'{data}{dataset}splits/{res}')\n",
    "\n",
    "train_classes = np.unique(np.squeeze([i[0][0] \\\n",
    "                                      for i in resnet101['labels'][train-1]]))\n",
    "\n",
    "test_classes = np.unique(np.squeeze([i[0][0] \\\n",
    "                                     for i in resnet101['labels'][test-1]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "digital-chart",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_data_loaders(class_idx, unseen_classes, seen_classes, \n",
    "                       seen_samples, unseen_samples, \n",
    "                       image_attr, embeddings, \n",
    "                       keep_train, index_train, \n",
    "                       dataset, seed=1, \n",
    "                       n_iter=3, max_iter=500):\n",
    "    \"\"\"Returns scores, num_examples, and saves and\n",
    "    returns list of models.\n",
    "    \"\"\"\n",
    "    \n",
    "    idx_unseen = sorted(unseen_classes)\n",
    "    idx_seen = sorted(seen_classes)\n",
    "    \n",
    "    # Split attribute matrices\n",
    "    img_att_seen = image_attr[[i[0] for i in seen_samples - 1]]\n",
    "    img_att_unseen = image_attr[[i[0] for i in unseen_samples - 1]]\n",
    "    #img_att_val = image_attr[val_samples-1]\n",
    "    \n",
    "    # Split feature matrices\n",
    "    X_tmp = embeddings.numpy()[[i[0] for i in seen_samples - 1]]\n",
    "    X_test = embeddings.numpy()[[i[0] for i in unseen_samples - 1]]\n",
    "\n",
    "    # Initialize return\n",
    "    scores = defaultdict(list)\n",
    "    num_examples = {}\n",
    "    models = {}\n",
    "    C, A = np.shape(M)\n",
    "    \n",
    "    for i,a in enumerate(tqdm(range(A))):\n",
    "        # Get examples with the attribute\n",
    "        print(img_att_seen.shape)\n",
    "        idx_attr = np.where(img_att_seen[:,a] > 0)[0]\n",
    "        idx_attr_test = np.where(img_att_unseen[:,a] > 0)[0]\n",
    "        \n",
    "        \n",
    "        # Assign o,1 labe to all the examples\n",
    "        y_tmp = np.array([1 if i in idx_attr else 0 \\\n",
    "                      for i in range(X_tmp.shape[0])])\n",
    "        y_test = np.array([1 if i in idx_attr_test else 0 \\\n",
    "                      for i in range(X_test.shape[0])])\n",
    "        \n",
    "        num_examples[a] = {\"Num pos train\":len(idx_attr),\n",
    "                           \"Num pos test\": len(idx_attr_test),\n",
    "                           \"Num neg train\": np.sum(y_tmp==0),\n",
    "                           \"Num neg test\": np.sum(y_test==0)}\n",
    "        \n",
    "        for s in range(n_iter):\n",
    "            # Train logistic models for different splits of train and validation\n",
    "            X_train, X_val, y_train, y_val = train_test_split(X_tmp, y_tmp, \n",
    "                                                              test_size=0.33, \n",
    "                                                              random_state=s)\n",
    "            \n",
    "            try:\n",
    "                clf = LogisticRegression(random_state=seed, \n",
    "                                         max_iter=max_iter, \n",
    "                                         class_weight='balanced'\n",
    "                                         ).fit(X_train, y_train)\n",
    "                \n",
    "                y_val_pred = clf.predict(X_val)\n",
    "                valpoint = clf.score(X_val, y_val)\n",
    "                balanced_val = balanced_accuracy_score(y_val, y_val_pred)\n",
    "                \n",
    "                y_test_pred = clf.predict(X_test)\n",
    "                testpoint = clf.score(X_test, y_test)\n",
    "                balanced_test = balanced_accuracy_score(y_test, y_test_pred)\n",
    "            \n",
    "            except ValueError:\n",
    "                print('Not samples from the two classes -> Assign -100 to identify nan')\n",
    "                scores[a] += [(-100,-100, -100, -100)]\n",
    "                continue\n",
    "                \n",
    "            scores[a] += [(valpoint, balanced_val, \n",
    "                           testpoint, balanced_test)]\n",
    "        \n",
    "        models[a] = clf\n",
    "          \n",
    "    with open(f'results/{dataset}detectors/score_detectors_held_out.pickle', 'wb') as handle:\n",
    "        pickle.dump(scores, \n",
    "                    handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "    with open(f'results/{dataset}detectors/models_held_out.pickle', 'wb') as handle:\n",
    "        pickle.dump(models, \n",
    "                    handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "            \n",
    "            \n",
    "    return scores, num_examples, models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fantastic-college",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores, num_examples, models = train_data_loaders(class_idx, train_classes, test_classes,\n",
    "                                                  train, test, class_attributes, \n",
    "                                                  image_attr, embeddings,\n",
    "                                                  dataset, seed=50, n_iter=1, max_iter=700)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
